---
title: "Homework 5"
author: "Riya Bhilegaonkar"
date: "2022-11-06"
output: html_document
---

```{r, include = FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(rvest)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

### Problem 2

The raw data contains information on more than 52,000 criminal homicides over the past decade in 50 of the largest American cities. The dataset contains the columns of `uid`, `reported`, `victim_last`, `victim_first`, `victim_age`,`victim_sex`, `city`, `state`, `lat`, `lon` and `disposition`. The data describes the location of the killing, whether an arrest was made and basic demographic information about each victim. 
```{r}
homicide_data = read_csv("data/homicide-data.csv") %>%
  mutate(city_state = str_c(city,    state, sep=", "),unsolved = ifelse((disposition=="Closed without arrest" | disposition =="Open/No arrest"), 1, 0)) 

city_state = homicide_data %>%
  group_by(city_state) %>%
  summarize("Total" = n(), "Unsolved" = sum(unsolved))
city_state %>%
knitr::kable()


```

Estimating the proportion of homicides that are unsolved:
```{r}
baltimore = homicide_data %>%
  filter(city_state=="Baltimore, MD")

 prop.test(x=sum(baltimore[["unsolved"]]), n=length(baltimore[["disposition"]]), conf.level=0.95) %>% 
  broom::tidy() %>%
   select(estimate, conf.low, conf.high)
```
Hence the estimated proportion is 0.646, the confidence interval for the proportion for the city of Baltimore, MD.

Running `prop.test` function to estimate the proportion of homicides, that are unsolved for each city. 
```{r}
city_state %>%
  mutate(prop = purrr::map2(Unsolved, Total, ~ prop.test(.x, .y, conf.level=0.95) %>%                   broom::tidy())) %>%
unnest(prop)%>%
select(city_state, estimate, conf.low, conf.high)%>%
knitr::kable()
```


Creating a plot for the estimates and CI's for each city, organizing the cities according to the proportion of unsolved homicides:
```{r}
city_state %>%
  mutate(prop = purrr::map2(Unsolved, Total, ~ prop.test(.x, .y, conf.level=0.95) %>%                   broom::tidy())) %>%
unnest(prop)%>%
select(city_state, estimate, conf.low, conf.high)%>%
mutate(city_state = fct_reorder(city_state, estimate))%>%
ggplot(aes(x=city_state, y=estimate))+
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
geom_errorbar(aes(ymin=conf.low, ymax=conf.high))

```

From the plot we see that Tulsa has the lowest proportion of unsolved homicides while Chicago has the highest proportion of unsolved homicides.

## Problem 3
Setting the design elements
```{r}
n = 30
sigma = 5
mu = 0
```

Writing a function to generate datasets from the model and conducting a simulation to explore power in a one-sample t-test:

```{r}
onesamp_test = function(n=30, mu, sigma = 5){
  sim_data = tibble(
    x = rnorm(n, mean=mu, sd=sigma)
  )
  
  t_test = t.test(sim_data, conf.level = 0.95) %>%
    broom::tidy()
}

```

Conducting the tests for $\mu=0$
```{r}
sim_results_df = 
  expand_grid(
    sample_size = 30,
    mu = 0,
    iter = 1:10
  ) %>% 
  mutate(
    estimate_df = map2(sample_size,mu, onesamp_test)
  ) %>% 
  unnest(estimate_df)

sim_results_df
```

Now repeating the above for $\mu={1,2,3,4,5,6}$:
```{r}
sim_results_df2 = 
  expand_grid(
    sample_size = 30,
    mu = c(1,2,3,4,5),
    iter = 1:10
  ) %>% 
  mutate(
    estimate_df = map2(.x=sample_size,.y=mu, ~onesamp_test(n = .x, mu =.y))
  ) %>% 
  unnest(estimate_df)

sim_results_df2
```

Making a plot showing the proportion of times the null was rejected on the y axis and the true value of $\mu$ on the x axis:
```{r}
sim_results_df2 %>%
  group_by(mu) %>%
  filter(p.value < 0.05) %>%
  summarize(proportion = n()) %>%
  ggplot(aes(x=mu, y=proportion/5000))+
  geom_point()+
  labs(x = "True value of mu",
       y = "Power of the test",
       title= "Association between effct size and power")
```


Make a plot showing the average $\hat{\mu}$ on the y-axis and the true value of $\mu$ on the x axis, and overlay the average estimate of $\hat{\mu}$ only in samples for which the null was rejected:
```{r}
sim_results_df2 %>%
  group_by(mu, estimate) %>%
  ggplot(aes(x=mu, y=mean(estimate)))+
  geom_point()+
  labs(x = "True value of mu",
       y = "Average estimate of mu_hat")
```





